#!/usr/bin/env groovy
@Grab(group='commons-cli', module='commons-cli', version='1.4')
@Grab(group='org.apache.commons', module='commons-lang3', version='3.4')
@Grab(group='edu.stanford.nlp', module='stanford-corenlp', version='3.7.0')
@Grab(group='edu.stanford.nlp', module='stanford-corenlp', version='3.7.0', classifier='models')
@Grab(group='edu.stanford.nlp', module='stanford-parser', version='3.7.0')
@Grab(group='org.codehaus.groovy.modules.http-builder', module='http-builder', version='0.7.1')
@Grab(group='org.apache.pdfbox', module='pdfbox', version='2.0.15')

import groovy.json.*
import klib.*
import java.util.concurrent.*
import java.util.concurrent.atomic.*
import groovyx.gpars.*
import org.codehaus.gpars.*

/**
 * Read command line input!
 */

def cliBuilder = new CliBuilder(
  usage: 'komenti <command> [<options>]',
  header: 'Options:'
)
cliBuilder.with {
  h longOpt: 'help', 'Print this help text and exit.'

  // query options
  o longOpt: 'ontology', 'Which ontology to query.', args: 1
  q longOpt: 'query', 'A Manchester OWL Syntax query, the result of which will be the set of NER labels.', args: '+'
  c longOpt: 'class-list', 'A list of classes to query. You can also pass a file, one label per line.', args: 1
  _ longOpt: 'object-properties', 'Query object properties (do not pass --query/-q or -c/--classes)', type: Boolean
  _ longOpt: 'query-type', 'Type of query to run. Either equivalent, subeq, superclass, subclass. Default is subeq', args: 1, defaultValue: 'subeq'
  _ longOpt: 'override-group', 'Override group in labels output with given text', args: 1
  _ longOpt: 'priority', 'RegexNER priority in output. Default is 1.', args: 1
  _ longOpt: 'expand-synonyms', 'Expand synonyms using AberOWL', type: Boolean

  // annotation options
  t longOpt: 'text', 'A file or directory of files to annotate.', args: 1
  l longOpt: 'labels', 'Annotation labels file.', args: 1
  _ longOpt: 'file-list', 'A file containing a list of strings file names in the directory given by -t/--text must contain to be annotated (e.g. pmcids)', args: 1
  _ longOpt: 'per-line', 'Process each line of each file seperately (useful for field-based data e.g. downloaded with get_metadata)', type: Boolean
  _ longOpt: 'disable-modifiers', 'Don\'t evaluate negation and uncertainty. The reason for this is: it takes a lot of time!', type: Boolean

  // summary options
  a longOpt: 'annotation-file', 'Annotation file to summarise', args: 1

  // auto option
  r longOpt: 'roster', 'The file to get the automatic order list from.', args: 1

  // genroster
  _ longOpt: 'with-abstracts-download', 'Generate a roster that downloads abstracts from PubMed Central.', type: Boolean
  _ longOpt: 'with-metadata-download', 'Generate a roster that downloads metadata for classes.', type: Boolean
  _ longOpt: 'mine-relationship', 'Generate a roster that mines text for a relationship between entities.', type: Boolean

  // genroster suggestaxiom options
  _ longOpt: 'default-relation', 'Default relation to use for suggest_axiom', args: 1
  _ longOpt: 'default-entity', 'Default entity to use for suggest_axiom', args: 1

  _ longOpt: 'suggest-axiom', 'Generate a roster that suggests an axiom for a class'
  _ longOpt: 'entity', 'Entity to query for (class name).', args: 1
  _ longOpt: 'quality', 'Quality to query for (class name).', args: 1
  eo longOpt: 'entity-ontology', 'Ontology to query for entities (if not included will use same as class query)', args: 1
  qo longOpt: 'quality-ontology', 'Ontology to query for qualities (if not included will use the same as class query)', args: 1
  oo longOpt: 'object-property-ontology', 'Ontology to get object properties from (if not included will use the same as class query)', args: 1

  // get_articles option (some also apply to get_metadata)
  _ longOpt: 'limit', 'Limit articles download', args: 1, type: Integer
  _ longOpt: 'group-by-query', 'Group classes by query (rather than URI)', type: Boolean
  _ longOpt: 'conjunction', 'Use a conjunctive query to obtain articles', type: Boolean
  _ longOpt: 'exclude-groups', 'Comma delimited list of groups to ignore for download query', args: 1
  _ longOpt: 'id-list-only', 'Only download a file list of', type: Boolean
  _ longOpt: 'lemmatise', 'Lemmatise the downloaded information. Can be used on query, download_metadata, download_abstracts', type: Boolean
  _ longOpt: 'decompose-entities', 'If the label of an entity (group class in the label file) appears in a string, decompose it in a new label', type: Boolean
  _ longOpt: 'count-only', 'Only provide the hit counts for the articles. This does not suffer from the article limit that downloads do!', type: Boolean

  // all options
  _ longOpt: 'out', 'Where to write the annotation results.', args: 1
  _ longOpt: 'append', 'Append output file, instead of replacing it', type: Boolean
  _ longOpt: 'verbose', 'Verbose output, mostly progress', type: Boolean
  _ longOpt: 'threads', 'Number of cores to use', type: Integer, args: 1, default: 1
}

run(cliBuilder, args)

def run(cliBuilder, args) {
  if(!args) { println "Must provide command." ; cliBuilder.usage() ; System.exit(1) }

  println args

  def command = args[0]
  def o = cliBuilder.parse(args.drop(1))

  if(o.h) { cliBuilder.usage() ; System.exit(0) }

  if(command == 'gen_roster') {
    if(!o.q && !o.c) { println "You must provide a query or class-list" ; cliBuilder.usage() ; System.exit(1) }
    if(!o.out) { println "Must provide place to save roster" ; cliBuilder.usage() ; System.exit(1) }
    if(!o['with-abstracts-download'] && !o['with-metadata-download'] && !o['mine-relationship'] && !o.t) { println "Must either download abstracts, metadata, or provide text to annotate" ; cliBuilder.usage() ; System.exit(1) }
    if(o['mine-relationship'] && (!o.c || (o.c && o.c.split(',').size() != 2))) { println "to --mine-relationship you must pass exactly two concept names with -c/--class-list" ; System.exit(1) }
    if(!o.o) { println "Must pass an ontology to query with -o/--ontology" ; System.exit(1) }
    if(o['suggest-axiom'] && (!o.c || (o.c && o.c.split(',').size() != 1) || !o.entity || !o.quality) || !o['default-entity'] || !o['default-relation'])  { println "to --suggest-axiom you must pass class lists for each -c, --entity, --quality. You must also pass --default-relation and --default-entity." ; System.exit(1) }

    def templateFile = new File('templates/roster.json')
    if(o['with-abstracts-download']) {
      templateFile = new File('templates/roster_with_abstract_download.json')
    }
    if(o['mine-relationship']) {
      templateFile = new File('templates/roster_mine_relationship.json')
    }
    if(o['suggest-axiom']) {
      templateFile = new File('templates/roster_suggest_axiom.json')
    }

    def roster = new JsonSlurper().parse(templateFile)
    
    // TODO this can probably mostly be automated
    if(o.q) {
      roster.commands.find { it.id == 'class_query' }.args.query = o.q
    } else {
      roster.commands.find { it.id == 'class_query' }.args['class-list'] = o.c
    }
    if(o.o) { roster.commands.find { it.id == 'class_query' }.args.ontology = o.o }

    if(o['with-abstracts-download']) {
      if(o.l) { roster.commands.find { it.command == 'get_abstracts' }.args.limit = o.l }
    }

    if(!o['with-abstracts-download'] && !o['with-metadata-download']) {
     roster.commands = roster.commands.findAll { it.command != 'get_abstracts' && it.command != 'get_metadata' }
     roster.commands.find { it.command == 'annotate' }.text = o.t 
    } else if(!o['with-abstracts-download']) {
     roster.commands = roster.commands.findAll { it.command != 'get_abstracts' }
    } else if(!o['with-metadata-download']) {
     roster.commands = roster.commands.findAll { it.command != 'get_metadata' }
    }

    if(o['mine-relationship']) {
      roster.commands.find { it.command == 'summarise_entity_pair' }.args['class-list'] = o.c
    }

    if(o['suggest-axiom']) {
      def cq = roster.commands.find { it.id == 'class_query' }
      cq.args['class-list'] = o.c
      cq.args['ontology'] = o.o

      def eq = roster.commands.find { it.id == 'entity_query' }
      eq.args['class-list'] = o.entity
      eq.args['ontology'] = o.eo ? o.eo : o.o

      def rq = roster.commands.find { it.id == 'relation_query' }
      rq.args['ontology'] = o.oo ? o.oo : o.o

      def qq = roster.commands.find { it.id == 'quality_query' }
      qq.args['class-list'] = o.quality
      qq.args['ontology'] = o.qo ? o.qo : o.o

      def sa = roster.commands.find { it.command == 'suggest_axiom' }
      sa.args['default-relation'] = o['default-relation']
      sa.args['default-entity'] = o['default-entity']
    }

    new File(o.out).text = JsonOutput.prettyPrint(JsonOutput.toJson(roster))
    println "Roster file saved to $o.out, where you can edit it manually. You can run it with 'groovy Komenti auto -r $o.out'"
  } else if(command == 'auto') {
    if(!o.r) { cliBuilder.usage() ; System.exit(1) }

    def roster = new JsonSlurper().parse(new File(o.r))

    roster.commands.each { item ->
      def newArgs = [item.command] + item.args.collect { k, v -> 
        if(k.size() == 1) { k = "-$k" } else { k = "--$k" } 
        if(v instanceof String && v.split(' ').size() > 1 && v[0] != '"') { v = '"' + v + '"' }
        if(v instanceof Integer || v instanceof Boolean) { v = "$v" } // foolish cliBuilder ...

        [k, v] 
      }.flatten()
      newArgs.removeAll("true")

      run(cliBuilder, newArgs)
    }
  } else if(command == 'query') {
    if((!o['object-properties'] && (!o.q && !o.c))) { cliBuilder.usage() ; System.exit(1) }
    if(o['object-properties'] && (o.q || o.c)) { println "Cannot pass a query or class list for --object-properties query" ; System.exit(1) }

    def labelOut = []
    def processEntities = { q, entities ->
      ConcurrentHashMap theseLabels = [:]
      def priority = o['priority'] ?: 1
      def i = 0
      GParsPool.withPool(o['threads']) { p ->
      entities.eachParallel{ e ->
        if(o['verbose']) { println "Synonym Expansion: ${++i}/${entities.size()}" }
        theseLabels[e.class] = KomentLib.AOExtractNames(e)
        if(o['expand-synonyms']) { // they will be made unique etc later
          theseLabels[e.class] += KomentLib.AOExpandSynonyms(e.owlClass, 
                                                             [e.label].flatten()[0].toLowerCase()) // ew
        }
      }
      }

      def labelCount = entities.collect { e -> theseLabels[e.class].size() }.sum()

      println "Received $labelCount labels from ${entities.size()} classes, for query \"$q\"."

      theseLabels.each { c, l ->
        if(o.lemmatise) {
          theseLabels[c] += Komentisto.getLemmas(l)
        }
        theseLabels[c].unique(true)
        theseLabels[c].findAll { it != '' }
      }

      if(o['override-group']) { q = o['override-group'] }
      theseLabels.collect { c, ls -> ls.collect { l -> "$l\t$c\t$q\t$o.o\t$priority" } }.flatten()
    }

    if(o['object-properties']) {
      KomentLib.AOGetObjectProperties(o.o, { oProps ->
        labelOut += processEntities('object-properties', oProps)
      })
    } else { // regular class query
      def queries = [o.q]
      if(o.c) {
        def f = new File(o.c)
        if(f.exists()) {
          queries = f.text.split('\n')
        } else {
          queries = o.c.split(',')
        }
      }
      
      queries.each { q ->
        def ont = o.o
        if(q.indexOf('\t') != -1) { (q, ont) = q.split('\t') }
        if(q.indexOf(' ') != -1) { q = "'" + q + "'" }
        KomentLib.AOSemanticQuery(q, ont, o['query-type'], { classes ->
          labelOut += processEntities(q, classes)
        })
      }
    }

    writeOutput(labelOut.join('\n'), o,
                "Saved ${labelOut.size()} labels to $o.out!")
  } else if(command == 'get_metadata') {
    if(!o.l) { println "Must pass label file" ; cliBuilder.usage() ; System.exit(1) }

    def outDir = getOutDir(o)
    def files = [:]
    def komentisto = new Komentisto(o.l, o['disable-modifiers'], o['threads'])

    def excludeGroups = []
    def entityLabels = []
    def classLabels = [:]
    if(o['exclude-groups']) {
      excludeGroups = o['exclude-groups'].split(',')
    }
    new File(o.l).splitEachLine('\t') { // TODO: integrate this into loadClassLabels
      if(it[2] == 'entity') { entityLabels << it[0].replaceAll('\\\\', '') }
      if(!excludeGroups.contains(it[2])) {
        if(!classLabels.containsKey(it[1])) { classLabels[it[1]] = [ l: [], o: it[3] ] }
          classLabels[it[1]].l << it[0]
        }
      }

    if(!o['decompose-entities']) { entityLabels = [] }

    classLabels.each { iri, l ->
      KomentLib.AOSemanticQuery("<$iri>", l.o, "equivalent", { classes ->
        // we want the actual class, not just semantically equivalent ones. although tbh it might be better to get the metadata from those too. it has to be semantically equivalent to this class, after all
        def c = classes.find { it.class == iri }
        def metadata = KomentLib.AOExtractMetadata(c, entityLabels)
        if(o['lemmatise']) { // we do it per line here, since it's a field based document
          metadata = metadata.split('\n').collect { komentisto.lemmatise(it) }.join('\n')
        }
        files[l.l[0]] = metadata
      })
    }

    println "Writing metadata files for ${files.size()} classes."
    files.each { n, c ->
      new File(outDir.getAbsolutePath() + '/' + n.replaceAll('/','') + '.txt').text = c
    } 

    println "Done"
  } else if(command == 'annotate') {
    if(!o.t || !o.l) { cliBuilder.usage() ; System.exit(1) }
    if(!o.out) { println "Must provide output filename via --out" ; System.exit(1) }

    def classLabels = loadClassLabels(o)
    def fList
    if(o['file-list']) {
      fList = new File(o['file-list']).text.split('\n')
    }

    def outWriter = new BufferedWriter(new FileWriter(o.out))

    def target = new File(o.t)
    def processFileOrDir
    processFileOrDir = { f, item -> 
      if(item.isDirectory()) {
        item.eachFile { processFileOrDir(f, it) }
      } else { 
        if(!fList || (fList && fList.contains(item.getName()))) {
          f << item
        }
      }
      f
    }
    files = processFileOrDir([], target)


    println "Annotating ${files.size()} files ..."
    def komentisto = new Komentisto(o.l, o['disable-modifiers'], o['threads'])
      
    def i = 0
    GParsPool.withPool(o['threads']) { p -> 
    files.eachParallel{ f ->
      def (name, text) = [f.getName(), f.text]
      if(name =~ /(?i)pdf/) { text = new PDFReader(f).getText() }

      if(o['per-line']) {
        text.tokenize('\n').eachWithIndex { lineText, z ->
          def annotations = komentisto.annotate(name, lineText, z+i)
          annotations.each { a ->
           outWriter.write([ a.f, 
              a.c,
              classLabels[a.c].l[0],
              a.tags.join(','),
              a.sid,
              a.text.replaceAll('\n', '')
            ].join('\t') + '\n')
          }
        }
      } else { 
        def annotations = komentisto.annotate(name, text)
        annotations.each { a ->
         outWriter.write([ a.f, 
            a.c,
            classLabels[a.c].l[0],
            a.tags.join(','),
            a.sid,
            a.text.replaceAll('\n', '')
          ].join('\t') + '\n')
        }
      }
      i++
      if((i % 500) == 0) { outWriter.flush() }
      if(o.verbose) {
        println "${i}/${files.size()}"
      }
    }
    }

    outWriter.flush()
    outWriter.close()
  } else if(command == 'add_modifiers') {
    if(!o.out || !o.a || !o.l) { println "Must provide annotation file via -a, and labels file with -l, and output filename via --out" ; System.exit(1) }
    def komentisto = new Komentisto(o.l, false)

    def newAnnotations = []
    def i = 0
    def aSize = new File(o.a).text.split('\n').size() // ugly

    def annoFile = []
    new File(o.a).splitEachLine('\t') { annoFile << it }

    def cache = []
    new File(o.out).splitEachLine('\t') { cache << it[0] }

    def outWriter = new BufferedWriter(new FileWriter(o.out, true));

    GParsPool.withPool(8) { p -> 
    annoFile.eachParallel {
      if(!cache.contains(it[0]) && it[1] && it[5]) {
        def res = komentisto.evaluateSentenceConcept(it[5], it[1])
        def tags = []
        if(res.negated) { tags << 'negated' }
        if(res.uncertain) { tags << 'uncertain' }
        it[3] = tags.join(',')

        outWriter.write(it.join('\t') + '\n')
        if(o.verbose) { println "Adding modifiers (${++i}/$aSize)" }
      } else {
        i++
      }
    }
    }

    outWriter.flush()
    outWriter.close()
  } else if(command == 'get_abstracts') {
    if(!o.l) { cliBuilder.usage() ; System.exit(1) }

    def outDir = getOutDir(o)
    def classLabels = [:] // TODO integrate this gIndex etc with the loadClassLabels function
    def gIndex = 1
    def excludeGroups = []
    if(o['exclude-groups']) {
      excludeGroups = o['exclude-groups'].split(',')
    }
    if(o['group-by-query']) {
      gIndex = 2
    }
    new File(o.l).splitEachLine('\t') { // TODO: integrate this into loadClassLabels
      if(!excludeGroups.contains(it[2])) {
        if(!classLabels.containsKey(it[gIndex])) { classLabels[it[gIndex]] = [] }
        classLabels[it[gIndex]] << it[0]
      }
    }

    println "Finding articles for ${classLabels.size()} classes ..."

    def aids = []
    if(o.conjunction) {
      def query = '(' + classLabels.collect { c, l -> '"' + l.join('" OR "') + '"' }.join(') AND (') + ')'
      KomentLib.PMCSearch(query, o['count-only'], { result -> aids << result })
    } else { // disjunction (default)
      def newLabels = []
      def thisLabelGroup = []
      classLabels.each { cls, labels ->
        thisLabelGroup << labels
        if(thisLabelGroup.size() == 10) {
          newLabels << thisLabelGroup.flatten()
          thisLabelGroup = []
        }
      }
      newLabels << thisLabelGroup.flatten()

      def i = 0
      newLabels.each { labels ->
        KomentLib.PMCSearchTerms(labels, o['count-only'], { result -> aids << result })
        println "${++i}/${newLabels.size()}"
      }
    }

    aids = aids.flatten()

    if(o['count-only']) {
      println "Found ${aids.sum()} articles ..."
    } else {
      println "Found ${aids.size()} articles ..."

      if(o.limit) { 
        aids = aids.subList(0, o.limit)
      }

      println "Downloading abstracts for ${aids.size()} articles ..."

      if(o['id-list-only']) {
        writeOutput(aids.join('\n'), o, "Saved pmcids to $o.out!")
      } else {
        def komentisto = new Komentisto(o.l, o['disable-modifiers'], threads)
        def abstracts = []
        aids.each { pmcid ->
          KomentLib.PMCGetAbstracts(pmcid, { a -> 
            if(a) { 
              if(o['lemmatise']) {
                a = komentisto.lemmatise(a)
              }
              abstracts << [ id: pmcid, text: a ]
            }
          })
        }

        println "Saving ${abstracts.size()} abstracts to ${outDir.getPath()}"

        abstracts.each { a ->
          new File(outDir.getAbsolutePath() + '/' + a.id + '.txt').text = a.text
        } 
      }
    }
  } else if(command == 'summarise_entity_pair') {
    if(!o.l || !o.a || !o.c) { cliBuilder.usage() ; System.exit(1) }
    def classes = o.c.split(',')
    def g1 = classes[0]
    def g2 = classes[1]

    def groupLabels = [:]
    def classLabels = [:]
    def classGroups = [:]
    new File(o.l).splitEachLine('\t') {
      if(it[2] == g1 || it[2] == g2) {
        if(!classLabels.containsKey(it[1])) { classLabels[it[1]] = [] }
        classLabels[it[1]] << it[0]

        if(!groupLabels.containsKey(it[2])) { groupLabels[it[2]] = [] }
        groupLabels[it[2]] << it[1]

        classGroups[it[1]] = it[2]
      } 
    }

    def fids = []
    def annotations = []
    new File(o.a).splitEachLine('\t') {  // TODO just use file headers for this
      annotations << [
        f: it[0],
        iri: it[1],
        label: it[2],
        tags: it[3],
        sid: it[4],
        text: it[5],
        group: classGroups[it[1]]
      ]
      fids << it[0]
    }

    fids.unique(true)

    def g1A = annotations.findAll { it.group == g1 }
    def g2A = annotations.findAll { it.group == g2 }

    println "$g1 is mentioned ${g1A.size()} times"
    println "$g2 is mentioned ${g2A.size()} times"

    // Group mentions by files

    def g1F = g1A.findAll { a -> g2A.find { it.f == a.f } }
    def bothMentionFiles = []

    g1F.each { a1 ->
      g2A.findAll { it.f == a1.f }.each { a2 ->
        bothMentionFiles << [ a1, a2 ]
      }
    }

    def bothCounts = [:]
    bothMentionFiles.each { l ->
      def key = l[0].label + ' and ' + l[1].label
      if(!bothCounts.containsKey(key)) {
        bothCounts[key] = [ count: 0, uncertain: 0, negated: 0, articles: [] ]
      }
      bothCounts[key].count++
      if(l[0].tags.contains('negated') || l[1].tags.contains('negated')) {
        bothCounts[key].negated++
      }
      if(l[0].tags.contains('uncertain') || l[1].tags.contains('uncertain')) {
        bothCounts[key].uncertain++
      }
      if(!bothCounts[key].articles.contains(l[0].f)) { bothCounts[key].articles << l[0].f }
    }

    println "Considered ${fids.size()} documents and ${annotations.size()} annotations"
    println "$g1 and $g2 are mentioned together ${bothMentionFiles.size()} times."
    bothCounts.each { key, c ->
      println "  $key ($c.count mentions, ${c.articles.size()} articles, $c.uncertain uncertain, $c.negated negated)"
    }
  } else if(command == 'suggest_axiom') {
    if(!o.l || !o.a) { println 'Must provide a --label file and a --annotations file to suggest_axiom' ; System.exit(1) }

    // TODO probably just put this into an Labels class, replacing the loadLabels
    def groupClasses = [:]
    def classes = [:]
    def entity
    def relation
    new File(o.l).splitEachLine('\t') {
      groupClasses[it[1]] = it[2]
      if(it[2] == 'class') {
        if(!classes.containsKey(it[1])) {
          classes[it[1]] = it[0]
        }
      }
      if(it[2] == 'entity' && it[0] == o['default-entity']) {
        entity = [
          iri: it[1],
          label: it[0].replaceAll('\\\\',''),
          count: 0
        ]
      }
      if(it[2] == 'relation' && it[0] == o['default-relation']) {
        relation = [
          iri: it[1],
          label: it[0].replaceAll('\\\\',''),
          count: 0
        ]
      }
    }

    if(!relation) { println "Could not find default relation in label file." ; System.exit(1) }
    if(!entity) { println "Could not find default entity in label file." ; System.exit(1) }

    // TODO put this into a load annotations
    // by files, sentences, annotation 
//    def annotations = [:]
    def sentences = [:]
    new File(o.a).splitEachLine('\t') {
      def sid = it[0] + ':' + it[4]
      if(!sentences.containsKey(sid)) { sentences[sid] = [] }
      sentences[sid] << [
        f: it[0],
        iri: it[1],
        label: it[2].replaceAll('\\\\',''),
        tags: it[3],
        sid: it[4],
        text: it[5],
        group: groupClasses[it[1]],
      ]
    }

    if(o['class-list']) { def cl = o['class-list'].split(',') ; classes = classes.findAll { cIRI, cLabel -> cl.contains(cLabel) } }

    classes.each { cIRI, cLabel ->
      def counts = [:]
      def qualityCounts = [:]
      def relationCounts = [:]
      def entityCounts = [:]

      // files that mention our class ...
      def classFiles = sentences.findAll { i, s -> s.any { it.f.indexOf(cLabel) != -1 } }.collect { i, s -> s.f }
      sentences.findAll { i, s -> classFiles.contains(s.f) }.each { id, annotations ->
        annotations.findAll { it.group == 'entity' }.each { tentity ->
          if(!entityCounts.containsKey(tentity.iri)) { entityCounts[tentity.iri] = [ iri: tentity.iri, label: tentity.label, sids: [], count: 0] }
          entityCounts[tentity.iri].count++
          entityCounts[tentity.iri].sids << id
        }
        annotations.findAll { it.group == 'quality' && it.iri != cIRI && it.label.indexOf(entity.label) == -1 }.each { quality ->
          if(quality) {
            if(!qualityCounts.containsKey(quality.iri)) { qualityCounts[quality.iri] = [ iri: quality.iri, label: quality.label, sids: [], count: 0] }
            qualityCounts[quality.iri].count++
            qualityCounts[quality.iri].sids << id
          }
        }
        annotations.findAll { it.group == 'relation' }.each { trelation ->
          if(trelation) {
            if(!relationCounts.containsKey(relation.iri)) { relationCounts[relation.iri] = [ iri: relation.iri, label: relation.label, sids: [], count: 0] }
            relationCounts[relation.iri].count++
            relationCounts[relation.iri].sids << id
          }
        }
      }

      if(qualityCounts.size() > 0) {
        def bestQuality = qualityCounts.collect { it.getValue() }.inject { s, c -> c.count > s.count ? c : s }
        def bestEntity = entityCounts.collect { it.getValue() }.inject(entity) { s, c -> c.count > s.count ? c : s }
        def bestRelation = relationCounts.collect { it.getValue() }.inject(relation) { s, c -> c.count > s.count ? c : s }

        println "Suggested axiom for $cLabel ($cIRI): "
          println "  $bestEntity.label AND ($bestRelation.label SOME $bestQuality.label)"
          println "  <$bestEntity.iri> AND (<$bestRelation.iri> SOME <$bestQuality.iri>)"
        println 'Evidence:'
        println '  ' + bestQuality.sids.join(',  ')
      } else {
        println "No qualities found for $cLabel ($cIRI)"
      }
      println ''
      //def bestRelation = relationCounts.inject { s, iri, c -> c.count > s.count ? c : s }
    }
  }
}

def writeOutput(text, o, success) {
  def oFile = new File(o.out)
  if(o.append) { text = oFile.text + '\n' + text }

  try {
    oFile.text = text
    println success
  } catch(e) { println 'Error: ' + e.getMessage() }
}

def loadClassLabels(o) {
  def classLabels = [:]
  new File(o.l).splitEachLine('\t') {
    if(!classLabels.containsKey(it[1])) { classLabels[it[1]] = [ l: [], o: it[3] ] }
    classLabels[it[1]].l << it[0]
  }
  classLabels
}

def getOutDir(o) {
  def outDir
  if(!o['count-only']) { outDir = new File(o.out) }
  if(!o['id-list-only'] && !o['count-only']) {
    if(!outDir.exists()) { outDir.mkdir() }
    if(!outDir.isDirectory()) { println "Must pass output directory (existing or not)" }
  }
  outDir
}
