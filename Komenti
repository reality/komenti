#!/usr/bin/env groovy
@Grab(group='commons-cli', module='commons-cli', version='1.4')
@Grab(group='org.apache.commons', module='commons-lang3', version='3.4')
@Grab(group='edu.stanford.nlp', module='stanford-corenlp', version='3.7.0')
@Grab(group='edu.stanford.nlp', module='stanford-corenlp', version='3.7.0', classifier='models')
@Grab(group='edu.stanford.nlp', module='stanford-parser', version='3.7.0')
@Grab(group='org.codehaus.groovy.modules.http-builder', module='http-builder', version='0.7.1')

import groovy.json.*
import klib.*
import java.util.concurrent.*
import java.util.concurrent.atomic.*
import groovyx.gpars.*
import org.codehaus.gpars.*

/**
 * Read command line input!
 */

def cliBuilder = new CliBuilder(
  usage: 'komenti <command> [<options>]',
  header: 'Options:'
)
cliBuilder.with {
	h longOpt: 'help', 'Print this help text and exit.'

    // query options
	o longOpt: 'ontology', 'Which ontology to query.', args: 1
	q longOpt: 'query', 'A Manchester OWL Syntax query, the result of which will be the set of NER labels.', args: '+'
    e longOpt: 'expand-labels', 'Expand the set of synonyms retrieved using syntactic methods.'
    c longOpt: 'class-list', 'A list of classes to get subclasses of', args: 1
    _ longOpt: 'object-properties', 'Query object properties (do not pass --query/-q or -c/--classes)', type: Boolean
    _ longOpt: 'query-type', 'Type of query to run. Either equivalent, subeq, superclass, subclass. Default is subeq', args: 1, defaultValue: 'subeq'
    _ longOpt: 'override-group', 'Override group in labels output with given text', args: 1

    // annotation options
	t longOpt: 'text', 'A file or directory of files to annotate.', args: 1
    l longOpt: 'labels', 'Annotation labels file.', args: 1
    _ longOpt: 'file-list', 'A file containing a list of strings file names in the directory given by -t/--text must contain to be annotated (e.g. pmcids)', args: 1
    _ longOpt: 'per-line', 'Process each line of each file seperately (useful for field-based data e.g. downloaded with get_metadata)', type: Boolean

    // summary options
    a longOpt: 'annotation-file', 'Annotation file to summarise', args: 1

    // auto option
    r longOpt: 'roster', 'The file to get the automatic order list from.', args: 1

    // genroster
    _ longOpt: 'with-abstracts-download', 'Generate a roster that downloads abstracts from PubMed Central to annotate, instead of using the file/directory referred to by -t/--text.', type: Boolean
    _ longOpt: 'mine-relationship', 'Generate a roster that mines text for a relationship between entities.', type: Boolean

    // genroster suggestaxiom options
    _ longOpt: 'relation', 'Relation to use for suggest_axiom', args: 1

    _ longOpt: 'suggest-axiom', 'Generate a roster that suggests an axiom for a class'
    _ longOpt: 'entity', 'Entity to query for (class name).', args: 1
    _ longOpt: 'quality', 'Quality to query for (class name).', args: 1
    eo longOpt: 'entity-ontology', 'Ontology to query for entities (if not included will use same as class query)', args: 1
    qo longOpt: 'quality-ontology', 'Ontology to query for qualities (if not included will use the same as class query)', args: 1
    oo longOpt: 'object-property-ontology', 'Ontology to get object properties from (if not included will use the same as class query)', args: 1

    // get_articles option (some also apply to get_metadata)
    _ longOpt: 'limit', 'Limit articles download', args: 1, type: Integer
    _ longOpt: 'group-by-query', 'Group classes by query (rather than URI)', type: Boolean
    _ longOpt: 'conjunction', 'Use a conjunctive query to obtain articles', type: Boolean
    _ longOpt: 'exclude-groups', 'Comma delimited list of groups to ignore for download query', args: 1
    _ longOpt: 'id-list-only', 'Only download a file list of', type: Boolean
    _ longOpt: 'lemmatise', 'Lemmatise the downloaded information', type: Boolean

    // all options
    _ longOpt: 'out', 'Where to write the annotation results.', args: 1
    _ longOpt: 'append', 'Append output file, instead of replacing it', type: Boolean
    _ longOpt: 'verbose', 'Verbose output, mostly progress', type: Boolean
}

run(cliBuilder, args)

def run(cliBuilder, args) {
  if(!args) { println "Must provide command." ; cliBuilder.usage() ; System.exit(1) }

  def command = args[0]
  def o = cliBuilder.parse(args.drop(1))

  if(o.h) { cliBuilder.usage() ; System.exit(0) }

  if(command == 'gen_roster') {
    if(!o.q && !o.c) { println "You must provide a query or class-list" ; cliBuilder.usage() ; System.exit(1) }
    if(!o.out) { println "Must provide place to save roster" ; cliBuilder.usage() ; System.exit(1) }
    if(!o['with-abstracts-download'] && !o['mine-relationship'] && !o.t) { println "Must either download abstracts or provide text to annotate" ; cliBuilder.usage() ; System.exit(1) }
    if(o['mine-relationship'] && (!o.c || (o.c && o.c.split(',').size() != 2))) { println "to --mine-relationship you must pass exactly two concept names with -c/--class-list" ; System.exit(1) }
    if(!o.o) { println "Must pass an ontology to query with -o/--ontology" ; System.exit(1) }
    if(o['suggest-axiom'] && (!o.c || (o.c && o.c.split(',').size() != 1) || !o.entity || !o.quality))  { println "to --suggest-axiom you must pass exactly one class with -c/--class-list and exactly one entity with --entity and exactly one quality with --quality" ; System.exit(1) }

    def templateFile = new File('templates/roster.json')
    if(o['with-abstracts-download']) {
      templateFile = new File('templates/roster_with_abstract_download.json')
    }
    if(o['mine-relationship']) {
      templateFile = new File('templates/roster_mine_relationship.json')
    }
    if(o['suggest-axiom']) {
      templateFile = new File('templates/roster_suggest_axiom.json')
    }

    def roster = new JsonSlurper().parse(templateFile)
    
    // TODO this can probably mostly be automated
    if(o.q) {
      roster.commands.find { it.id == 'class_query' }.args.query = o.q
    } else {
      roster.commands.find { it.id == 'class_query' }.args['class-list'] = o.c
    }
    if(o.o) { roster.commands.find { it.id == 'class_query' }.args.ontology = o.o }
    if(!o['with-abstracts-download'] && !o['mine-relationship']) {
      roster.commands.find { it.command == 'annotate' }.args.text = o.t
    } else {
      if(o.l) { roster.commands.find { it.command == 'get_abstracts' }.args.limit = o.l }
    }

    if(o['mine-relationship']) {
      roster.commands.find { it.command == 'summarise_entity_pair' }.args['class-list'] = o.c
    }

    if(o['suggest-axiom']) {
      def cq = roster.commands.find { it.id == 'class_query' }
      cq.args['class-list'] = o.c
      cq.args['ontology'] = o.o

      def eq = roster.commands.find { it.id == 'entity_query' }
      eq.args['class-list'] = o.entity
      eq.args['ontology'] = o.eo ? o.eo : o.o

      def rq = roster.commands.find { it.id == 'relation_query' }
      rq.args['ontology'] = o.oo ? o.oo : o.o

      def qq = roster.commands.find { it.id == 'quality_query' }
      qq.args['class-list'] = o.quality
      qq.args['ontology'] = o.qo ? o.qo : o.o

      if(!o['with-abstracts-download']) {
        roster = roster.findAll { it.command != get_abstracts }
        roster.find { it.command == 'annotate' }.text = o.t 
      }
    }

    new File(o.out).text = JsonOutput.prettyPrint(JsonOutput.toJson(roster))
    println "Roster file saved to $o.out, where you can edit it manually. You can run it with 'groovy Komenti auto -r $o.out'"
  } else if(command == 'auto') {
    if(!o.r) { cliBuilder.usage() ; System.exit(1) }

    def roster = new JsonSlurper().parse(new File(o.r))

    roster.commands.each { item ->
      def newArgs = [item.command] + item.args.collect { k, v -> 
        if(k.size() == 1) { k = "-$k" } else { k = "--$k" } 
        if(v instanceof String && v.split(' ').size() > 1 && v[0] != '"') { v = '"' + v + '"' }
        if(v instanceof Integer || v instanceof Boolean) { v = "$v" } // foolish cliBuilder ...

        [k, v] 
      }.flatten()
      newArgs.removeAll("true")

      run(cliBuilder, newArgs)
    }
  } else if(command == 'query') {
    if(!o.o || (!o['object-properties'] && (!o.q && !o.c))) { cliBuilder.usage() ; System.exit(1) }
    if(o['object-properties'] && (o.q || o.c)) { println "Cannot pass a query or class list for --object-properties query" ; System.exit(1) }

    def labelOut = []
    def processEntities = { q, entities ->
      def theseLabels = [:]
      entities.each { e -> theseLabels[e.class] = KomentLib.AOExtractNames(e) }

      def labelCount = entities.collect { e -> theseLabels[e.class].size() }.sum()

      println "Received $labelCount labels from ${entities.size()} classes, for query \"$q\"."

      theseLabels.each { c, l ->
        if(o.e) {
          theseLabels[c] += Komentisto.getLemmas(l)
        }
        theseLabels[c].unique(true)
        theseLabels[c].findAll { it != '' }
      }

      if(o['override-group']) { q = o['override-group'] }
      theseLabels.collect { c, ls -> ls.collect { l -> "$l\t$c\t$q\t$o.o" } }.flatten()
    }

    if(o['object-properties']) {
      KomentLib.AOGetObjectProperties(o.o, { oProps ->
        labelOut += processEntities('object-properties', oProps)
      })
    } else { // regular class query
      def queries = [o.q]
      if(o.c) {
        queries = o.c.split(',')
        queries = queries.collect{ if(it.indexOf(' ') != -1) { it = "'" + it + "'" } ; it }
      }
      
      queries.each { q ->
        KomentLib.AOSemanticQuery(q, o.o, o['query-type'], { classes ->
          labelOut += processEntities(q, classes)
        })
      }
    }

    writeOutput(labelOut.join('\n'), o,
                "Saved ${labelOut.size()} labels to $o.out!")
  } else if(command == 'get_metadata') {
    if(!o.l) { println "Must pass label file" ; cliBuilder.usage() ; System.exit(1) }

    def outDir = getOutDir(o)
    def classLabels = loadClassLabels(o)
    def files = [:]
    def komentisto = new Komentisto(o.l)
    
    classLabels.each { iri, l ->
      KomentLib.AOSemanticQuery("<$iri>", l.o, "equivalent", { classes ->
        // we want the actual class, not just semantically equivalent ones. although tbh it might be better to get the metadata from those too. it has to be semantically equivalent to this class, after all
        def c = classes.find { it.class == iri }
        def metadata = KomentLib.AOExtractMetadata(c)
        if(o['lemmatise']) { // we do it per line here, since it's a field based document
          metadata = metadata.split('\n').collect { komentisto.lemmatise(it) }.join('\n')
        }
        files[l.l[0]] = metadata
      })
    }

    println "Writing metadata files for ${files.size()} classes."
    files.each { n, c ->
      new File(outDir.getAbsolutePath() + '/' + n + '.txt').text = c
    } 

    println "Done"
  } else if(command == 'annotate') {
    if(!o.t || !o.l) { cliBuilder.usage() ; System.exit(1) }
    if(!o.out) { println "Must provide output filename via --out" ; System.exit(1) }

    def classLabels = loadClassLabels(o)
    def fList
    if(o['file-list']) {
      fList = new File(o['file-list']).text.split('\n').collect { it + '.txt' }
    }

    def target = new File(o.t)
    def processFileOrDir
    processFileOrDir = { f, item -> 
        if(item.isDirectory()) {
          item.eachFile { processFileOrDir(f, it) }
        } else { 
          if(!fList || (fList && fList.contains(item.getName()))) {
            f << item
          }
        }
      f
    }
    files = processFileOrDir([], target)

    def komentisto = new Komentisto(o.l)

    println "Annotating ${files.size()} files ..."

    def i = 0
    def annotations = []
//    GParsPool.withPool(8) { p -> 
    files.each{ f ->
      if(o['per-line']) {
        f.text.tokenize('\n').each { lineText ->
          annotations << komentisto.annotate(f.getName(), lineText)
        }
      } else {
        annotations << komentisto.annotate(f.getName(), f.text)
      }
      if(o.verbose) {
        println "${++i}/${files.size()}"
      }
    }
 //   }
    annotations = annotations.flatten()
    annotations.removeAll([null])

    println "Found ${annotations.size()} annotations"

    def out = annotations.collect { a -> 
      [ a.f, 
        a.c,
        classLabels[a.c].l[0],
        a.tags.join(','),
        a.sid,
        a.text.replaceAll('\n', '')
      ].join('\t')
    }.join('\n')
    writeOutput(out, o, "Saved annotations to $o.out!")
  } else if(command == 'get_abstracts') {
    if(!o.l) { cliBuilder.usage() ; System.exit(1) }

    def outDir = getOutDir(o)
    def classLabels = [:] // TODO integrate this gIndex etc with the loadClassLabels function
    def gIndex = 1
    def excludeGroups = []
    if(o['exclude-groups']) {
      excludeGroups = o['exclude-groups'].split(',')
    }
    if(o['group-by-query']) {
      gIndex = 2
    }
    new File(o.l).splitEachLine('\t') { // TODO: integrate this into loadClassLabels
      if(!excludeGroups.contains(it[2])) {
        if(!classLabels.containsKey(it[gIndex])) { classLabels[it[gIndex]] = [] }
        classLabels[it[gIndex]] << it[0]
      }
    }

    println "Finding articles for ${classLabels.size()} classes ..."

    def aids = []
    if(o.conjunction) {
      def query = '(' + classLabels.collect { c, l -> '"' + l.join('" OR "') + '"' }.join(') AND (') + ')'
      KomentLib.PMCSearch(query, { result -> aids << result })
    } else { // disjunction (default)
      def newLabels = []
      def thisLabelGroup = []
      classLabels.each { cls, labels ->
        thisLabelGroup << labels
        if(thisLabelGroup.size() == 10) {
          newLabels << thisLabelGroup.flatten()
          thisLabelGroup = []
        }
      }

      def i = 0
      newLabels.each { labels ->
        KomentLib.PMCSearchTerms(labels, { result -> aids << result })
        println "${++i}/${newLabels.size()}"
      }
    }

    aids = aids.flatten()

    println "Found ${aids.size()} articles ..."

    if(o.limit) { 
      aids = aids.subList(0, o.limit)
    }

    println "Downloading abstracts for ${aids.size()} articles ..."

    if(o['id-list-only']) {
      writeOutput(aids.join('\n'), o, "Saved pmcids to $o.out!")
    } else {
      def komentisto = new Komentisto(o.l)
      def abstracts = []
      aids.each { pmcid ->
        KomentLib.PMCGetAbstracts(pmcid, { a -> 
          if(a) { 
            if(o['lemmatise']) {
              a = komentisto.lemmatise(a)
            }
            abstracts << [ id: pmcid, text: a ]
          }
        })
      }

      println "Saving ${abstracts.size()} abstracts to ${outDir.getPath()}"

      abstracts.each { a ->
        new File(outDir.getAbsolutePath() + '/' + a.id + '.txt').text = a.text
      } 
    }
  } else if(command == 'summarise_entity_pair') {
    if(!o.l || !o.a || !o.c) { cliBuilder.usage() ; System.exit(1) }
    def classes = o.c.split(',')
    def g1 = classes[0]
    def g2 = classes[1]

    def groupLabels = [:]
    def classLabels = [:]
    def classGroups = [:]
    new File(o.l).splitEachLine('\t') {
      if(it[2] == g1 || it[2] == g2) {
        if(!classLabels.containsKey(it[1])) { classLabels[it[1]] = [] }
        classLabels[it[1]] << it[0]

        if(!groupLabels.containsKey(it[2])) { groupLabels[it[2]] = [] }
        groupLabels[it[2]] << it[1]

        classGroups[it[1]] = it[2]
      } 
    }

    def fids = []
    def annotations = []
    new File(o.a).splitEachLine('\t') {  // TODO just use file headers for this
      annotations << [
        f: it[0],
        iri: it[1],
        label: it[2],
        tags: it[3],
        sid: it[4],
        text: it[5],
        group: classGroups[it[1]]
      ]
      fids << it[0]
    }

    fids.unique(true)

    def g1A = annotations.findAll { it.group == g1 }
    def g2A = annotations.findAll { it.group == g2 }

    println "$g1 is mentioned ${g1A.size()} times"
    println "$g2 is mentioned ${g2A.size()} times"

    // Group mentions by files

    def g1F = g1A.findAll { a -> g2A.find { it.f == a.f } }
    def bothMentionFiles = []

    g1F.each { a1 ->
      g2A.findAll { it.f == a1.f }.each { a2 ->
        bothMentionFiles << [ a1, a2 ]
      }
    }

    def bothCounts = [:]
    bothMentionFiles.each { l ->
      def key = l[0].label + ' and ' + l[1].label
      if(!bothCounts.containsKey(key)) {
        bothCounts[key] = [ count: 0, uncertain: 0, negated: 0, articles: [] ]
      }
      bothCounts[key].count++
      if(l[0].tags.contains('negated') || l[1].tags.contains('negated')) {
        bothCounts[key].negated++
      }
      if(l[0].tags.contains('uncertain') || l[1].tags.contains('uncertain')) {
        bothCounts[key].uncertain++
      }
      if(!bothCounts[key].articles.contains(l[0].f)) { bothCounts[key].articles << l[0].f }
    }

    println "Considered ${fids.size()} documents and ${annotations.size()} annotations"
    println "$g1 and $g2 are mentioned together ${bothMentionFiles.size()} times."
    bothCounts.each { key, c ->
      println "  $key ($c.count mentions, ${c.articles.size()} articles, $c.uncertain uncertain, $c.negated negated)"
    }
  } else if(command == 'suggest_axiom') {
    if(!o.l || !o.a) { println 'Must provide a --label file and a --annotations file to suggest_axiom' ; System.exit(1) }

    // TODO probably just put this into an Labels class, replacing the loadLabels
    def groupClasses = [:]
    def classes = [:]
    def entity
    def relation
    new File(o.l).splitEachLine('\t') {
      groupClasses[it[1]] = it[2]
      if(it[2] == 'class') {
        if(!classes.containsKey(it[1])) {
          classes[it[1]] = it[0]
        }
      }
      if(it[2] == 'entity') {
        entity = [
          iri: it[1],
          label: it[0]
        ]
      }
      if(it[2] == 'relation' && it[0] == o['relation']) {
        relation = [
          iri: it[1],
          label: it[0]
        ]
      }
    }

    // TODO put this into a load annotations
    // by files, sentences, annotation 
//    def annotations = [:]
    def sentences = [:]
    new File(o.a).splitEachLine('\t') {
      def sid = it[0] + ':' + it[4]
      if(!sentences.containsKey(sid)) { sentences[sid] = [] }
      sentences[sid] << [
        f: it[0],
        iri: it[1],
        label: it[2],
        tags: it[3],
        sid: it[4],
        text: it[5],
        group: groupClasses[it[1]],
      ]
    }

    classes.each { cIRI, cLabel ->
      def counts = [:]
      def qualityCounts = [:]
      def relationCounts = [:]
      def entityAndQualitySentence

      // files that mention our class ...
      def classFiles = sentences.findAll { i, s -> s.any { it.iri == cIRI } }.collect { i, s -> s.f }
      sentences.findAll { i, s -> classFiles.contains(s.f) }.each { id, annotations ->

        def tentity  = annotations.find { it.group == 'entity' }
        def quality = annotations.find { it.group == 'quality' && it.iri != cIRI }
        //def relation = annotations.find { it.group == 'relation' }

        if(tentity && quality) {
          entityAndQualitySentence = quality
        }

        if(quality) {
          if(!qualityCounts.containsKey(quality.iri)) { qualityCounts[quality.iri] = [ iri: quality.iri, label: quality.label, sids: [], count: 0] }
          qualityCounts[quality.iri].count++
          qualityCounts[quality.iri].sids << id
        }

        /*if(relation) {
          if(!relationCounts.containsKey(relation.iri)) { relationCounts[relation.iri] = [ iri: relation.iri, label: relation.label, sids: [], count: 0] }
          relationCounts[relation.iri].count++
          relationCounts[relation.iri].sids << id
        }*/
      }

      if(qualityCounts.size() > 0) {
        def bestQuality = qualityCounts.collect { it.getValue() }.inject { s, c -> c.count > s.count ? c : s } // for some reason you cannot give it three args
        //bestQuality = bestQuality.getValue()

        //bestQuality = bestQuality.getValue()

        println "Suggested axiom for $cLabel ($cIRI): "
          println "  $entity.label AND ($relation.label SOME $bestQuality.label)"
          println "  <$entity.iri> AND (<$relation.iri> SOME <$bestQuality.iri>)"
        println 'Evidence:'
        println '  ' + bestQuality.sids.join('\n  ')
      } else {
        println "No qualities found for $cLabel ($cIRI)"
      }
      //def bestRelation = relationCounts.inject { s, iri, c -> c.count > s.count ? c : s }
    }
  }
}

def writeOutput(text, o, success) {
  def oFile = new File(o.out)
  if(o.append) { text = oFile.text + '\n' + text }

  try {
    oFile.text = text
    println success
  } catch(e) { println 'Error: ' + e.getMessage() }
}

def loadClassLabels(o) {
  def classLabels = [:]
  new File(o.l).splitEachLine('\t') {
    if(!classLabels.containsKey(it[1])) { classLabels[it[1]] = [ l: [], o: it[3] ] }
    classLabels[it[1]].l << it[0]
  }
  classLabels
}

def getOutDir(o) {
  def outDir = new File(o.out)
  if(!o['id-list-only']) {
    if(!outDir.exists()) { outDir.mkdir() }
    if(!outDir.isDirectory()) { println "Must pass output directory (existing or not)" }
  }
  outDir
}
